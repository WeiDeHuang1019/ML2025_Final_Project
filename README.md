# ML2025_Final_Project
當然可以 
以下是一份簡潔、期末專題報告適用的 **README 草稿**（採中英雙語、語氣自然、不艱深），適合放在 GitHub 專案首頁或期末投影片摘要裡。

---

#  Dino-AI: 自動學會玩 Google 小恐龍的機器學習專題

*(Dino-AI: Machine Learning Agent for the Google Chrome Dino Game)*

##  專案簡介 (Overview)

本專題目標是讓電腦**自動學會玩 Google Chrome 的離線恐龍遊戲**，
不使用任何手刻規則（rule-based），而是**透過觀察人類的示範畫面與操作紀錄進行學習**。

最終，AI 能根據螢幕畫面判斷何時跳躍、蹲下或保持原地，
在遊戲速度逐漸加快的情況下，自主做出即時反應並成功避開障礙。

---

##  專案概念 (Core Idea)

這是一個典型的「**行為模仿學習 (Behavior Cloning)**」應用。
我們先錄製人類玩家的遊戲過程（包含畫面與按鍵），再讓模型學習這些對應關係。

| 步驟          | 說明                               |
| ----------- | -------------------------------- |
|  **資料收集** | 擷取遊戲畫面並記錄人類玩家的按鍵動作     |
|  **特徵學習** | 將畫面轉成灰階影像，堆疊連續幀讓模型看出移動趨勢         |
|  **模型訓練** | 使用 CNN 模型學習「當畫面呈現這樣的情況時，人會做什麼動作」 |
|  **自動遊玩** | 以訓練好的模型即時預測動作，控制恐龍跳躍或閃避障礙        |

---

## 使用技術 (Tech Stack)

* **Python 3.10**
* **OpenCV** – 擷取與前處理遊戲畫面
* **PyTorch** – 建立與訓練卷積神經網路 (CNN)
* **pynput / pyautogui** – 模擬鍵盤輸入控制遊戲

##  專案目標 (Expected Results)

* 模型能根據畫面自動判斷 **何時跳躍、何時蹲下**。
* 當遊戲速度變快時，模型會自然學會「**提早起跳**」的行為。
* 不需要任何手刻規則或特徵判斷（完全基於資料學習）。

---

##  預期成果與應用 (Expected Outcomes)

* 展示 **AI 如何透過觀察學習人類行為**。
* 建立一個可延伸的遊戲自動化框架，可套用至其他簡易 2D 遊戲。
* 作為進一步研究強化學習 (Reinforcement Learning) 的基礎。



